{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "from implicit.cpu.bpr import BayesianPersonalizedRanking\n",
    "from implicit.cpu.lmf import LogisticMatrixFactorization\n",
    "from implicit.evaluation import precision_at_k,mean_average_precision_at_k\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from recometrics import split_reco_train_test,calc_reco_metrics\n",
    "from cmfrec import MostPopular\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "DATASET = 'DatasetsWtime'\n",
    "PULSE_RED = f'{DATASET}/pulse_red.csv'\n",
    "ARTICLE_CORE = f'{DATASET}/article_core.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pulse_red = pd.read_csv(PULSE_RED, index_col=[0], low_memory=False)\n",
    "df_pulse_red.loc[df_pulse_red['views'] > 1, 'views'] = 1\n",
    "df_pulse_red"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove direkte articles and article published outside timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_core = pd.read_csv(ARTICLE_CORE)\n",
    "section_of_article = {row[\"article_id\"]: row[\"section_title\"] for index, row in df_article_core.iterrows()}\n",
    "direkte_articles = [row['article_id'] for index, row in df_article_core.iterrows() if row['section_title']=='Direkte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id_to_keep = list(set(section_of_article.keys())-set(direkte_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pulse_red_article_keep = df_pulse_red.loc[df_pulse_red['article_id'].isin(article_id_to_keep)]\n",
    "df_pulse_red_article_keep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove environment ids (not registrered users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spids_without_cookies = []\n",
    "for i in set(df_pulse_red_article_keep.spid):\n",
    "    if i.isdigit():\n",
    "        spids_without_cookies.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_cookies = df_pulse_red_article_keep.loc[df_pulse_red_article_keep.spid.isin(spids_without_cookies)]\n",
    "df_without_cookies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove articles read by only one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_reads = df_without_cookies.groupby(by='article_id')['views'].count().sort_values(ascending=False)\n",
    "article_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_reads = df_without_cookies.groupby(by='article_id')['views'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlestokeep = article_reads>=2\n",
    "articlestokeep = list(articlestokeep[articlestokeep].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_article_reads = df_without_cookies.loc[df_without_cookies['article_id'].isin(articlestokeep)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove users that hasnt read one article per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = df_pulse_red['published_date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_deltas = [datetime_object + timedelta(days=i) for i in range(7,57,7)]\n",
    "time_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = str(datetime_object)\n",
    "spids_to_keep = []\n",
    "for i,e in enumerate(time_deltas):\n",
    "    to = str(e)\n",
    "    temp_df = df_min_article_reads[df_min_article_reads['published_date'].between(start,to)]\n",
    "    temp_spids = set(temp_df['spid'])\n",
    "    if i == 0:\n",
    "        spids_to_keep = list(set(temp_df['spid']))\n",
    "    spids_to_keep = list(set(spids_to_keep) & set(temp_df['spid']))\n",
    "    if i != 7:\n",
    "        start = str(e)\n",
    "print(len(spids_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pulse_red_one_article_per_week = df_min_article_reads.loc[df_min_article_reads['spid'].isin(spids_to_keep)]\n",
    "df_pulse_red_one_article_per_week"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep dataframe for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_pulse_red_one_article_per_week.drop('published_date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_pr.reset_index().drop('index',axis=1)\n",
    "df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_pr.loc[(df_pr.spid.notnull()) & (df_pr.article_id.notnull())]\n",
    "df_pr['spid'] = df_pr['spid'].astype('category')\n",
    "df_pr['article_id'] = df_pr['article_id'].astype('category')\n",
    "df_pr.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "X = coo_matrix((df_pr.views, (df_pr.spid.cat.codes, df_pr.article_id.cat.codes)))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_reco, X_train_reco, X_test_reco, test_users_reco = \\\n",
    "    split_reco_train_test(\n",
    "        X, split_type=\"separated\",\n",
    "        users_test_fraction = 0.2,\n",
    "        max_test_users=20000,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random and Most popular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRandomAndMostPopular(fit_set,train_set,test_set):\n",
    "    rng = np.random.default_rng(seed=1)\n",
    "    UserFactors_random = rng.standard_normal(size=(test_set.shape[0], 5))\n",
    "    ItemFactors_random = rng.standard_normal(size=(test_set.shape[1], 5))\n",
    "\n",
    "    ### Non-personalized recommendations\n",
    "    model_baseline = MostPopular(implicit=True, user_bias=False).fit(fit_set)\n",
    "    item_biases = model_baseline.item_bias_\n",
    "    item_biases\n",
    "\n",
    "    k=5\n",
    "    metrics_random = calc_reco_metrics(\n",
    "        #X_train[:X_test.shape[0]]\n",
    "        train_set[:test_set.shape[0]], test_set,\n",
    "        UserFactors_random, ItemFactors_random,\n",
    "        k=k, all_metrics=True\n",
    "    )\n",
    "    metrics_baseline = calc_reco_metrics(\n",
    "        #X_train[:X_test.shape[0]]\n",
    "        train_set[:test_set.shape[0]], test_set,\n",
    "        None, None, item_biases=item_biases,\n",
    "        k=k, all_metrics=True\n",
    "    )\n",
    "    \n",
    "    all_metrics = [\n",
    "    metrics_random,\n",
    "    metrics_baseline\n",
    "    ]\n",
    "    all_metrics = pd.concat([m.mean(axis=0).to_frame().T for m in all_metrics], axis=0)\n",
    "    all_metrics.index = [\n",
    "        \"Random\",\n",
    "        \"Most Popular\"\n",
    "    ]\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random_most_popular = calculateRandomAndMostPopular(X_fit_reco,X_train_reco,X_test_reco)\n",
    "results_random_most_popular.to_csv('../Results/randomAndMostPopular_hyper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Results/randomAndMostPopular_hyper.csv','w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['metric','P@5','TP@5','R@5','AP@5','TAP@5','NDCG@5','Hit@5','RR@5','ROC_AUC','PR-AUC'])\n",
    "    randomAndMostPopular_metrics = calculateRandomAndMostPopular(X_fit_reco,X_train_reco,X_test_reco)\n",
    "    writer.writerow(['Random',randomAndMostPopular_metrics['P@5']['Random'],randomAndMostPopular_metrics['TP@5']['Random'],randomAndMostPopular_metrics['R@5']['Random'],randomAndMostPopular_metrics['AP@5']['Random'],randomAndMostPopular_metrics['TAP@5']['Random'],randomAndMostPopular_metrics['NDCG@5']['Random'],randomAndMostPopular_metrics['Hit@5']['Random'],randomAndMostPopular_metrics['RR@5']['Random'],randomAndMostPopular_metrics['ROC_AUC']['Random'],randomAndMostPopular_metrics['PR_AUC']['Random']])\n",
    "    writer.writerow(['Most Popular',randomAndMostPopular_metrics['P@5']['Most Popular'],randomAndMostPopular_metrics['TP@5']['Most Popular'],randomAndMostPopular_metrics['R@5']['Most Popular'],randomAndMostPopular_metrics['AP@5']['Most Popular'],randomAndMostPopular_metrics['TAP@5']['Most Popular'],randomAndMostPopular_metrics['NDCG@5']['Most Popular'],randomAndMostPopular_metrics['Hit@5']['Most Popular'],randomAndMostPopular_metrics['RR@5']['Most Popular'],randomAndMostPopular_metrics['ROC_AUC']['Most Popular'],randomAndMostPopular_metrics['PR_AUC']['Most Popular']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ALS(fit_set,train_set,test_set,fac,ite,reg):\n",
    "    k=5\n",
    "    ALSmodel = AlternatingLeastSquares(factors=fac,iterations=ite,regularization=reg)\n",
    "    ALSmodel.fit(fit_set)\n",
    "\n",
    "    metrics_als = calc_reco_metrics(\n",
    "        train_set[:test_set.shape[0]], test_set,\n",
    "        ALSmodel.user_factors[:test_set.shape[0]], ALSmodel.item_factors,\n",
    "        k=k, all_metrics=True\n",
    "    )\n",
    "\n",
    "    all_metrics = [\n",
    "    metrics_als\n",
    "    ]\n",
    "    all_metrics = pd.concat([m.mean(axis=0).to_frame().T for m in all_metrics], axis=0)\n",
    "    all_metrics.index = [\n",
    "        \"ALS\"\n",
    "    ]\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALSfactors = [5,10,15,30,60,100]\n",
    "ALSiterations = [5,10,15,30,60,100]\n",
    "ALSregularization = [0.001,0.01,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "k=5\n",
    "with open('../Results/ALS_hyper.csv','w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['model','k','factor','iteration','regularization','P@5','TP@5','R@5','AP@5','TAP@5','NDCG@5','Hit@5','RR@5','ROC_AUC','PR_AUC'])\n",
    "    model_name = 'ALS'\n",
    "    for fac in ALSfactors:\n",
    "        for ite in ALSiterations:\n",
    "            for reg in ALSregularization:\n",
    "                temp_metric = calculate_ALS(X_fit_reco,X_train_reco,X_test_reco,fac,ite,reg)\n",
    "                writer.writerow([model_name,k,fac,ite,reg,temp_metric['P@5'][model_name],temp_metric['TP@5'][model_name],temp_metric['R@5'][model_name],temp_metric['AP@5'][model_name],temp_metric['TAP@5'][model_name],temp_metric['NDCG@5'][model_name],temp_metric['Hit@5'][model_name],temp_metric['RR@5'][model_name],temp_metric['ROC_AUC'][model_name],temp_metric['PR_AUC'][model_name]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_BPR(fit_set,train_set,test_set,fac,ite,reg,learning):\n",
    "    k=5\n",
    "    BPRmodel = BayesianPersonalizedRanking(factors=fac,iterations=ite,regularization=reg,learning_rate=learning)\n",
    "    BPRmodel.fit(fit_set)\n",
    "\n",
    "    metrics_bpr = calc_reco_metrics(\n",
    "        train_set[:test_set.shape[0]], test_set,\n",
    "        BPRmodel.user_factors[:test_set.shape[0]], BPRmodel.item_factors,\n",
    "        k=k, all_metrics=True\n",
    "    )\n",
    "\n",
    "    all_metrics = [\n",
    "    metrics_bpr\n",
    "    ]\n",
    "    all_metrics = pd.concat([m.mean(axis=0).to_frame().T for m in all_metrics], axis=0)\n",
    "    all_metrics.index = [\n",
    "        \"BPR\"\n",
    "    ]\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPRfactors = [5,10,15,30,60,100]\n",
    "BPRiterations = [5,10,15,30,60,100]\n",
    "BPRregularization = [0.001,0.01,0.1]\n",
    "BPRlearning_rates = [0.001,0.01,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "with open('../Results/BPR_hyper.csv','w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['model','k','factor','iteration','regularization','learning_rate','P@5','TP@5','R@5','AP@5','TAP@5','NDCG@5','Hit@5','RR@5','ROC_AUC','PR_AUC'])\n",
    "    model_name = 'BPR'\n",
    "    for fac in BPRfactors:\n",
    "        for ite in BPRiterations:\n",
    "            for reg in BPRregularization:\n",
    "                for learning in BPRlearning_rates:\n",
    "                    temp_metric = calculate_BPR(X_fit_reco,X_train_reco,X_test_reco,fac,ite,reg,learning)\n",
    "                    writer.writerow([model_name,k,fac,ite,reg,learning,temp_metric['P@5'][model_name],temp_metric['TP@5'][model_name],temp_metric['R@5'][model_name],temp_metric['AP@5'][model_name],temp_metric['TAP@5'][model_name],temp_metric['NDCG@5'][model_name],temp_metric['Hit@5'][model_name],temp_metric['RR@5'][model_name],temp_metric['ROC_AUC'][model_name],temp_metric['PR_AUC'][model_name]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning LMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_LMF(fit_set,train_set,test_set,fac,ite,reg,learning):\n",
    "    k=5\n",
    "    LMFmodel = LogisticMatrixFactorization(factors=fac,iterations=ite,regularization=reg,learning_rate=learning)\n",
    "    LMFmodel.fit(fit_set)\n",
    "\n",
    "    metrics_lmf = calc_reco_metrics(\n",
    "        train_set[:test_set.shape[0]], test_set,\n",
    "        LMFmodel.user_factors[:test_set.shape[0]], LMFmodel.item_factors,\n",
    "        k=k, all_metrics=True\n",
    "    )\n",
    "\n",
    "    all_metrics = [\n",
    "    metrics_lmf\n",
    "    ]\n",
    "    all_metrics = pd.concat([m.mean(axis=0).to_frame().T for m in all_metrics], axis=0)\n",
    "    all_metrics.index = [\n",
    "        \"LMF\"\n",
    "    ]\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMFfactors = [5,10,15,30,60,100]\n",
    "LMFiterations = [5,10,15,30,60,100]\n",
    "LMFregularization = [0.001,0.01,0.1,0.3,0.6,1.0]\n",
    "LMFlearning_rates = [0.001,0.01,0.1,0.3,0.6,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "with open('../Results/LMF_hyper.csv','w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['model','k','factor','iteration','regularization','learning_rate','P@5','TP@5','R@5','AP@5','TAP@5','NDCG@5','Hit@5','RR@5','ROC_AUC','PR_AUC'])\n",
    "    model_name = 'LMF'\n",
    "    for fac in LMFfactors:\n",
    "        for ite in LMFiterations:\n",
    "            for reg in LMFregularization:\n",
    "                for learning in LMFlearning_rates:\n",
    "                    temp_metric = calculate_LMF(X_fit_reco,X_train_reco,X_test_reco,fac,ite,reg,learning)\n",
    "                    writer.writerow([model_name,k,fac,ite,reg,learning,temp_metric['P@5'][model_name],temp_metric['TP@5'][model_name],temp_metric['R@5'][model_name],temp_metric['AP@5'][model_name],temp_metric['TAP@5'][model_name],temp_metric['NDCG@5'][model_name],temp_metric['Hit@5'][model_name],temp_metric['RR@5'][model_name],temp_metric['ROC_AUC'][model_name],temp_metric['PR_AUC'][model_name]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
